# -*- coding: utf-8 -*-
"""cats_vs_dogs_comparesion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZHwAiPwb7Dj4Jhj9XJQHw1B8BVOZdyrN
"""



from google.colab import files
files.upload()   # choose kaggle.json file

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!pip install kaggle

!kaggle datasets download -d moazeldsokyx/dogs-vs-cats

!unzip dogs-vs-cats.zip -d dogs_vs_cats

import os
import random
import matplotlib.pyplot as plt
from PIL import Image

dataset_path = "/content/dogs_vs_cats"

# Collect all image paths
image_paths = []
for root, dirs, files in os.walk(dataset_path):
    for file in files:
        if file.lower().endswith((".jpg", ".jpeg", ".png")):
            image_paths.append(os.path.join(root, file))

print("Total images found:", len(image_paths))

# Select 10 random images
sample_images = random.sample(image_paths, 10)

# Display them
plt.figure(figsize=(15, 10))

for i, img_path in enumerate(sample_images):
    img = Image.open(img_path)
    plt.subplot(2, 5, i+1)
    plt.imshow(img)
    plt.title(os.path.basename(img_path))
    plt.axis("off")

plt.tight_layout()
plt.show()

fimport tensorflow as tf
from tensorflow.keras import layers, models, Input
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
import os

dataset_dir = "/content/dogs_vs_cats/dataset"
train_dir = os.path.join(dataset_dir, "train")
val_dir = os.path.join(dataset_dir, "validation")
test_dir = os.path.join(dataset_dir, "test")

IMG_SIZE = (227, 227)
BATCH_SIZE = 16
EPOCHS = 1

train_ds = image_dataset_from_directory(train_dir,
                                        labels='inferred',
                                        label_mode='binary',
                                        image_size=IMG_SIZE,
                                        batch_size=BATCH_SIZE,
                                        shuffle=True)

val_ds = image_dataset_from_directory(val_dir,
                                      labels='inferred',
                                      label_mode='binary',
                                      image_size=IMG_SIZE,
                                      batch_size=BATCH_SIZE,
                                      shuffle=False)

test_ds = image_dataset_from_directory(test_dir,
                                       labels='inferred',
                                       label_mode='binary',
                                       image_size=IMG_SIZE,
                                       batch_size=BATCH_SIZE,
                                       shuffle=False)

AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)
test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)

inputs = Input(shape=(*IMG_SIZE, 3))
x = layers.Rescaling(1./255)(inputs)  # normalize

# Conv Layers
x = layers.Conv2D(96, 11, strides=4, activation='relu')(x)
x = layers.MaxPooling2D(3, strides=2)(x)

x = layers.Conv2D(256, 5, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(3, strides=2)(x)

x = layers.Conv2D(384, 3, padding='same', activation='relu')(x)
x = layers.Conv2D(384, 3, padding='same', activation='relu')(x)
x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)
x = layers.MaxPooling2D(3, strides=2)(x)

x = layers.Flatten()(x)

# Build base model and freeze it
base_model = models.Model(inputs=inputs, outputs=x)
base_model.trainable = False

x = base_model.output
x = layers.Dense(1024, activation='relu')(x)
x = layers.Dropout(0.5)(x)
x = layers.Dense(512, activation='relu')(x)
x = layers.Dropout(0.5)(x)
outputs = layers.Dense(1, activation='sigmoid')(x)  # binary classification

model = models.Model(inputs=base_model.input, outputs=outputs)

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.summary()

callbacks = [
    ModelCheckpoint("alexnet_transfer_best.h5", save_best_only=True, monitor='val_accuracy', verbose=1),
    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)
]

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=15,
    callbacks=callbacks
)

test_loss, test_acc = model.evaluate(test_ds)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}")

IMG_SIZE = (160, 160)
BATCH_SIZE = 32

data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
])

train_ds = image_dataset_from_directory(train_dir,
                                        labels='inferred',
                                        label_mode='binary',
                                        image_size=IMG_SIZE,
                                        batch_size=BATCH_SIZE,
                                        shuffle=True)

val_ds = image_dataset_from_directory(val_dir,
                                      labels='inferred',
                                      label_mode='binary',
                                      image_size=IMG_SIZE,
                                      batch_size=BATCH_SIZE,
                                      shuffle=False)

test_ds = image_dataset_from_directory(test_dir,
                                       labels='inferred',
                                       label_mode='binary',
                                       image_size=IMG_SIZE,
                                       batch_size=BATCH_SIZE,
                                       shuffle=False)

AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)
test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)

base_model = tf.keras.applications.MobileNetV2(input_shape=(*IMG_SIZE,3),
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False  # Freeze base

inputs = Input(shape=(*IMG_SIZE,3))
x = data_augmentation(inputs)
x = tf.keras.applications.mobilenet_v2.preprocess_input(x)  # preprocess
x = base_model(x, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3)(x)
outputs = layers.Dense(1, activation='sigmoid')(x)  # binary

model = models.Model(inputs, outputs)
model.summary()

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# -----------------------------
# 7️⃣ Callbacks
# -----------------------------
callbacks = [
    ModelCheckpoint("mobilenetv2_best.h5", save_best_only=True, monitor='val_accuracy', verbose=1),
    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)
]

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=5,
    callbacks=callbacks
)

test_loss, test_acc = model.evaluate(test_ds)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}")

import matplotlib.pyplot as plt
import numpy as np

class_names = ['cats', 'dogs']  # your class names

for images, labels in test_ds.take(1):
    preds = model.predict(images)
    preds_labels = (preds > 0.5).astype(int)

    batch_size = len(images)
    n_cols = 4
    n_rows = (batch_size + n_cols - 1) // n_cols  # auto rows

    plt.figure(figsize=(n_cols*4, n_rows*4))
    for i in range(batch_size):
        plt.subplot(n_rows, n_cols, i+1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(f"Actual: {class_names[int(labels[i])]}\nPred: {class_names[preds_labels[i][0]]}")
        plt.axis("off")
    plt.tight_layout()
    plt.show()
    break

import matplotlib.pyplot as plt

# Get history
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(len(acc))

# Plot Accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Train Accuracy', marker='o')
plt.plot(epochs_range, val_acc, label='Validation Accuracy', marker='o')
plt.title('Training vs Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Train Loss', marker='o')
plt.plot(epochs_range, val_loss, label='Validation Loss', marker='o')
plt.title('Training vs Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()